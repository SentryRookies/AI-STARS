# batch/keyword/keyword_extractor.py
import pandas as pd
from sentence_transformers import SentenceTransformer, util
from typing import List, Dict, Tuple

# 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer("jhgan/ko-sbert-nli")

# 2. í‚¤ì›Œë“œ ë§¤í•‘ (positive/negative)
positive_keyword_mapping = {
    "ì „ë°˜ì ": [
        "ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì•˜ì–´ìš”,",
        "ë‹¤ìŒì— ë‹¤ì‹œ ì˜¤ê³  ì‹¶ì–´ìš”",
        "ì´ ì¥ì†Œë¥¼ ì¶”ì²œí•´ìš”"
    ],
    "ê³µê°„": [
        "ê³µê°„ì´ ì¾Œì í–ˆì–´ìš”.",
        "ê³µê¸°ê°€ ë§‘ì•˜ì–´ìš”."
    ],
    "ìœ„ìƒ": [
        "ì „ì²´ì ìœ¼ë¡œ ê¹¨ë—í–ˆì–´ìš”.",
        "ì²­ì†Œê°€ ì˜ ë˜ì–´ ìˆì—ˆì–´ìš”.",
        "ìœ„ìƒ ìƒíƒœê°€ ì¢‹ì•˜ì–´ìš”."
    ],
    "ì¬ë¯¸": [
        "ì•„ì´ë“¤ì´ ì¦ê±°ì›Œí–ˆì–´ìš”.",
        "ë†€ ê±°ë¦¬ê°€ ë§ì•˜ì–´ìš”.",
        "ë³¼ ê±°ë¦¬ê°€ ë§ì•˜ì–´ìš”"
    ],
    "ìŒì‹": [
        "ìŒì‹ì´ ì •ë§ ë§›ìˆì—ˆì–´ìš”.",
        "ìŒì‹ì˜ ë§›ì´ í›Œë¥­í–ˆì–´ìš”.",
        "ìŒì‹ì˜ ë§›ì´ ê¸°ëŒ€ ì´ìƒì´ì—ˆì–´ìš”.",
        "ì´ ìŒì‹ì„ ì¶”ì²œí•´ìš”",
        "ìŒì‹ ì–‘ì´ ì¶©ë¶„í•´ìš”.",
        "ìŒì‹ ì–‘ì´ ì ë‹¹í•´ìš”",
        "ë°°ë¶€ë¥´ê²Œ ë¨¹ì—ˆì–´ìš”."
    ],
    "ë¶„ìœ„ê¸°": [
        "ë¶„ìœ„ê¸°ê°€ ì•„ëŠ‘í–ˆì–´ìš”.",
        "ë¶„ìœ„ê¸°ê°€ ë§¤ìš° í¸ì•ˆí–ˆì–´ìš”.",
        "ì¡°ìš©í•œ ë¶„ìœ„ê¸°ì˜€ì–´ìš”.",
        "ë¶„ìœ„ê¸°ê°€ ì¢‹ì•„ìš”."
    ],
    "ì„œë¹„ìŠ¤": [
        "ì„œë¹„ìŠ¤ê°€ ì •ë§ í›Œë¥­í–ˆì–´ìš”.",
        "ì§ì›ë“¤ì´ ì¹œì ˆí•˜ê³  ì‘ëŒ€ê°€ ì¢‹ì•˜ì–´ìš”.",
        "ì‘ëŒ€ê°€ ì •ì¤‘í•˜ê³  í¸ì•ˆí–ˆì–´ìš”.",
        "ì•ˆë‚´ê°€ ì˜ ë˜ì–´ ìˆì–´ì„œ í¸ë¦¬í–ˆì–´ìš”."
    ],
    "ì„ íƒì§€/ë©”ë‰´": [
        "ë©”ë‰´ê°€ ë‹¤ì–‘í•˜ê³  ì„ íƒì˜ í­ì´ ë„“ì—ˆì–´ìš”.",
        "ë©”ë‰´ê°€ í’ì„±í•˜ê³  ë§Œì¡±ìŠ¤ëŸ¬ì› ì–´ìš”.",
        "ë‹¤ì–‘í•œ ë©”ë‰´ê°€ ìˆì–´ì„œ ê³ ë¥´ê¸° ì¢‹ì•˜ì–´ìš”."
    ],
    "ê°€ê²©": [
        "ê°€ê²©ì´ í•©ë¦¬ì ì´ì—ˆì–´ìš”.",
        "ê°€ê²© ëŒ€ë¹„ ë§Œì¡±ë„ê°€ ë†’ì•˜ì–´ìš”.",
        "ê°€ê²©ì´ ì ë‹¹í•´ì„œ ë§Œì¡±í–ˆì–´ìš”."
    ],
    "ëŒ€ê¸°ì‹œê°„": [
        "ëŒ€ê¸°ì‹œê°„ì´ ì§§ì•„ìš”",
        "ëŒ€ê¸°ì‹œê°„ì´ ë¹ ë¥´ê²Œ ì§€ë‚˜ê°”ì–´ìš”."
    ],
    "ì „ë§/ê²½ì¹˜": [
        "ì „ë§ì´ ë©‹ì¡Œì–´ìš”.",
        "ê²½ì¹˜ê°€ íƒ íŠ¸ì—¬ì„œ ì¢‹ì•˜ì–´ìš”.",
        "ì „ë§ì´ í›Œë¥­í–ˆì–´ìš”."
    ],
    "ì ‘ê·¼ì„±": [
        "ìœ„ì¹˜ê°€ ì •ë§ í¸ë¦¬í–ˆì–´ìš”.",
        "ì°¾ê¸° ì‰¬ìš´ ìœ„ì¹˜ì˜€ì–´ìš”.",
        "ì ‘ê·¼í•˜ê¸° í¸í–ˆì–´ìš”."
    ],
    "ì£¼ì°¨": [
        "ì£¼ì°¨ ê³µê°„ì´ ì¶©ë¶„í–ˆì–´ìš”",
        "ì£¼ì°¨ê°€ ì•„ì£¼ ì‰¬ì› ì–´ìš”.",
        "ì£¼ì°¨ì¥ì´ ë„“ì–´ì„œ í¸í•˜ê²Œ ì£¼ì°¨í–ˆì–´ìš”."
    ],
    "ì „ì‹œ/ê´€ëŒ": [
        "ê´€ëŒí•˜ê¸° ì¢‹ì•˜ì–´ìš”.",
        "ì „ì‹œê°€ ì˜ êµ¬ì„±ë˜ì–´ ìˆì–´ìš”.",
        "ê´€ëŒí•  ì‹œê°„ì´ ì˜ ë°°ë¶„ë˜ì–´ ìˆì–´ìš”.",
        "ì‚¬ì§„ì´ ì˜ ë‚˜ì™€ìš”."
    ],
    "í˜¼ì¡": [
        "í˜¼ì¡í•˜ì§€ ì•Šì•„ìš”.",
        "ì‚¬ëŒì´ ë§ì§€ ì•Šì•„ìš”.",
        "ì‚¬ëŒì´ ì—†ì–´ìš”.",
        "ê´€ê´‘ê°ì´ ë§ì§€ ì•Šì•„ìš”"
    ],
    "ì‹œì„¤": [
        "í¸ì˜ì‹œì„¤ì´ ì˜ ê°–ì¶°ì ¸ ìˆì–´ìš”.",
        "ì‹œì„¤ì´ ì˜ ê´€ë¦¬ë˜ì–´ ìˆì—ˆì–´ìš”.",
        "í¸ì˜ì‹œì„¤ì´ ë§ì•„ ì´ìš©ì´ í¸ë¦¬í–ˆì–´ìš”."
    ],
    "ì˜ˆì•½": [
        "ì˜ˆì•½í•˜ê¸° í¸í•´ìš”",
        "ì˜ˆì•½ ì‹œìŠ¤í…œì´ ì˜ ê°–ì¶”ì–´ì ¸ ìˆì–´ìš”"
    ],
    "ë‚ ì”¨":[
        "ë‚ ì”¨ê°€ ì¢‹ì•˜ì–´ìš”",
        "ë°”ëŒì´ ì‹œì›í•˜ê²Œ ë¶ˆì—ˆì–´ìš”."
    ]
}

negative_keyword_mapping = {
    "ì „ë°˜ì ": [
        "ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì§€ ì•Šì•˜ì–´ìš”.",
        "ë‹¤ìŒì— ë‹¤ì‹œ ì˜¤ê³  ì‹¶ì§€ ì•Šì•„ìš”",
        "ì „ë°˜ì ìœ¼ë¡œ ì•„ì‰¬ì›Œìš”"
    ],
    "ê³µê°„": [
        "ê³µê°„ì´ ì¢ì•„ìš”.",
        "ê³µê¸°ê°€ íƒí•´ìš”.",
        "ê³µê°„ ë‚´ë¶€ê°€ ë„ˆë¬´ ì¶”ì›Œìš”",
        "ê³µê°„ ë‚´ë¶€ê°€ ë„ˆë¬´ ë”ì›Œìš”"
    ],
    "ìœ„ìƒ": [
        "ì „ì²´ì ìœ¼ë¡œ ë”ëŸ¬ì› ì–´ìš”.",
        "ì²­ì†Œê°€ ì˜ ë˜ì–´ ìˆì§€ ì•Šì•˜ì–´ìš”.",
        "ìœ„ìƒ ìƒíƒœê°€ ì¢‹ì§€ ì•Šì•˜ì–´ìš”.",
        "ê¹¨ë—í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”",
        "ë²Œë ˆê°€ ë§ì•„ìš”"
    ],
    "ì¬ë¯¸": [
        "ë†€ ê±°ë¦¬ê°€ ë¶€ì¡±í–ˆì–´ìš”.",
        "ë³¼ ê±°ë¦¬ê°€ ë¶€ì¡±í–ˆì–´ìš”"
    ],
    "ìŒì‹": [
        "ìŒì‹ì´ ë§›ì´ ë³„ë¡œì˜€ì–´ìš”.",
        "ìŒì‹ì˜ ë§›ì´ ê¸°ëŒ€ ì´í•˜ì˜€ì–´ìš”.",
        "ìŒì‹ì´ ì§œìš”.",
        "ìŒì‹ì˜ ì—¼ë„ê°€ ë†’ì•˜ì–´ìš”",
        "ìŒì‹ì´ ì‹±ê±°ì›Œìš”.",
        "ìŒì‹ì˜ ë§›ì´ ê·¸ëƒ¥ ê·¸ë˜ìš”." ,
        "ìŒì‹ ì–‘ì´ ì ì–´ìš”.",
        "ìŒì‹ ì–‘ì´ ë§ì•˜ìœ¼ë©´ ì¢‹ê² ì–´ìš”"
    ],
    "ë¶„ìœ„ê¸°": [
        "ë¶„ìœ„ê¸°ê°€ ë„ˆë¬´ ì–´ë‘ì› ì–´ìš”.",
        "ì‹œë„ëŸ¬ìš´ ë¶„ìœ„ê¸°ì˜€ì–´ìš”.",
        "ì¡°ìš©í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”"
    ],
    "ì„œë¹„ìŠ¤": [
        "ì„œë¹„ìŠ¤ê°€ ë¶ˆì¹œì ˆí–ˆì–´ìš”.",
        "ì§ì›ë“¤ì˜ ì‘ëŒ€ê°€ ë‚˜ë¹´ì–´ìš”.",
        "ì‘ëŒ€ê°€ ëŠë¦¬ê³  ë¶ˆí¸í–ˆì–´ìš”.",
        "ì¹œì ˆí–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”",
        "ì•ˆë‚´ê°€ ë¶€ì¡±í•´ì„œ ì°¾ê¸° í˜ë“¤ì—ˆì–´ìš”."
    ],
    "ì„ íƒì§€/ë©”ë‰´": [
        "ë©”ë‰´ê°€ ì œí•œì ì´ì—ˆì–´ìš”.",
        "ë©”ë‰´ê°€ ë¶€ì¡±í–ˆì–´ìš”.",
        "ë©”ë‰´ê°€ ì—†ì–´ì„œ ì•„ì‰¬ì› ì–´ìš”.",
        "ì„ íƒì§€ê°€ ë‹¤ì–‘í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”"
    ],
    "ê°€ê²©": [
        "ê°€ê²©ì´ ë¹„ìŒŒì–´ìš”.",
        "ê°€ê²© ëŒ€ë¹„ ë§Œì¡±ë„ê°€ ë‚®ì•˜ì–´ìš”.",
        "ê°€ì„±ë¹„ê°€ ì¢‹ì§€ ì•Šì•˜ì–´ìš”.",
        "ì¶”ê°€ ë¹„ìš©ì´ ë°œìƒí–ˆì–´ìš”"
    ],
    "ëŒ€ê¸°ì‹œê°„": [
        "ëŒ€ê¸°ì‹œê°„ì´ ê¸¸ì—ˆì–´ìš”.",
        "ëŒ€ê¸°ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¸ì–´ìš”."
    ],
    "ì „ë§/ê²½ì¹˜": [
        "ì „ë§ì´ ì¢‹ì§€ ì•Šì•˜ì–´ìš”.",
        "ê²½ì¹˜ê°€ ê°€ë ¤ì ¸ ìˆì—ˆì–´ìš”."
    ],
    "ì ‘ê·¼ì„±": [
        "ìœ„ì¹˜ê°€ ë¶ˆí¸í–ˆì–´ìš”.",
        "ìœ„ì¹˜ê°€ ë©€ì—ˆì–´ìš”.",
        "ìœ„ì¹˜ê°€ ì™¸ì¡Œì–´ìš”."
    ],
    "ì£¼ì°¨": [
        "ì£¼ì°¨ ê³µê°„ì´ ë¶€ì¡±í–ˆì–´ìš”.",
        "ì£¼ì°¨ê°€ ì–´ë ¤ì› ì–´ìš”.",
        "ì£¼ì°¨ì¥ì´ í˜‘ì†Œí–ˆì–´ìš”.",
        "ì£¼ì°¨ê°€ í¸ë¦¬í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”"
    ],
    "ì „ì‹œ/ê´€ëŒ": [
        "ê´€ëŒ í™˜ê²½ì´ ë¶ˆí¸í–ˆì–´ìš”.",
        "ì „ì‹œê°€ ì œëŒ€ë¡œ êµ¬ì„±ë˜ì§€ ì•Šì•˜ì–´ìš”.",
        "ê´€ëŒ ì‹œê°„ì´ ë¶€ì¡±í–ˆì–´ìš”.",
        "ê´€ëŒ í™˜ê²½ì´ ì¢‹ì•˜ìœ¼ë©´ ì¢‹ê² ì–´ìš”",
        "ì‚¬ì§„ì´ ì˜ ì•ˆ ë‚˜ì™€ìš”"
    ],
    "í˜¼ì¡": [
        "í˜¼ì¡í–ˆì–´ìš”.",
        "ì‚¬ëŒì´ ë§ì•˜ì–´ìš”.",
        "í˜¼ì¡í•˜ì§€ ì•Šì•˜ìœ¼ë©´ ì¢‹ê² ì–´ìš”",
        "ê´€ê´‘ê°ì´ ë§ì•„ìš”",
        "ìë¦¬ê°€ ì—†ì–´ìš”"
    ],
    "ì‹œì„¤": [
        "í¸ì˜ì‹œì„¤ì´ ë¶€ì¡±í–ˆì–´ìš”.",
        "ì‹œì„¤ì´ ì œëŒ€ë¡œ ê´€ë¦¬ë˜ì§€ ì•Šì•˜ì–´ìš”.",
        "ì‹œì„¤ì´ ë¶ˆí¸í•´ìš”",
        "ê°€êµ¬ê°€ ë¶ˆí¸í•´ìš”",
        "ì‹œì„¤ì´ í¸ë¦¬í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”"
    ],
    "ì˜ˆì•½": [
        "ì˜ˆì•½ì´ ì‰½ì§€ ì•Šì•„ìš”",
        "ì˜ˆì•½ ë°©ì‹ì´ ë¶ˆí¸í•´ìš”",
        "ì˜ˆì•½ì´ í¸ë¦¬í•´ì¡Œìœ¼ë©´ ì¢‹ê² ì–´ìš”"
    ],
    "ë‚ ì”¨":[
        "ë‚ ì”¨ê°€ ì¢‹ì§€ ì•Šì•˜ì–´ìš”",
        "ë‚ ì”¨ê°€ ì¶”ì›Œìš”",
        "ë‚ ì”¨ê°€ ë”ì›Œìš”",
        "ë°”ëŒì´ ë„ˆë¬´ ê°•í•´ìš”."
    ],
    "í”¼ë¡œ": [
        "ì²´ë ¥ì ìœ¼ë¡œ í˜ë“¤ì—ˆì–´ìš”.",
        "ì²´ë ¥ì ìœ¼ë¡œ ì§€ì³¤ì–´ìš”.",
        "ê±¸ìŒì´ ë„ˆë¬´ í˜ë“¤ì—ˆì–´ìš”."
    ]
}


# 3. í‚¤ì›Œë“œ ë§¤ì¹­ í•¨ìˆ˜
def get_top_keyword_and_score(text: str, keyword_dict: Dict) -> pd.Series:
    text_embedding = model.encode(text, convert_to_tensor=True)
    scores = {}
    best_sentence = ""
    best_score = -1

    for keyword, reps in keyword_dict.items():
        rep_embeddings = model.encode(reps, convert_to_tensor=True)
        score = util.pytorch_cos_sim(text_embedding, rep_embeddings).max().item()
        scores[keyword] = score

        if score > best_score:
            best_score = score
            best_sentence = reps[reps.index(
                max(reps, key=lambda x: util.pytorch_cos_sim(
                    text_embedding, model.encode(x, convert_to_tensor=True)).item()
                )
            )]

    top_keyword = max(scores, key=scores.get)
    return pd.Series([top_keyword, best_sentence, best_score])

# 4. ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_top_keywords(analyzed_data: List[Dict], save: bool = False, prefix: str = "result") -> Tuple[List[str], List[str]]:
    df = pd.DataFrame(analyzed_data)

    # ê°ì • í•„í„°ë§
    positive_df = df[df["label"] == "positive"].copy()
    negative_df = df[df["label"] == "negative"].copy()

    # í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼ ì €ì¥ìš©
    positive_keywords = []
    negative_keywords = []

    # ê¸ì • ë¦¬ë·° í‚¤ì›Œë“œ ì¶”ì¶œ
    # positive_results = positive_df["text"].apply(lambda x: get_top_keyword_and_score(x, positive_keyword_mapping))
    # positive_df["keyword"] = positive_results.apply(lambda x: x[0] if isinstance(x, (list, tuple, pd.Series)) else None)
    # positive_df["similar_sentence"] = positive_results.apply(lambda x: x[1] if isinstance(x, (list, tuple, pd.Series)) else None)
    # positive_df["score"] = positive_results.apply(lambda x: x[2] if isinstance(x, (list, tuple, pd.Series)) else None)

    # ë¶€ì • ë¦¬ë·° í‚¤ì›Œë“œ ì¶”ì¶œ
    # negative_results = negative_df["text"].apply(lambda x: get_top_keyword_and_score(x, negative_keyword_mapping))
    # negative_df["keyword"] = negative_results.apply(lambda x: x[0] if isinstance(x, (list, tuple, pd.Series)) else None)
    # negative_df["similar_sentence"] = negative_results.apply(lambda x: x[1] if isinstance(x, (list, tuple, pd.Series)) else None)
    # negative_df["score"] = negative_results.apply(lambda x: x[2] if isinstance(x, (list, tuple, pd.Series)) else None)

    # ê¸ì • ë¦¬ë·° í‚¤ì›Œë“œ ì¶”ì¶œ
    positive_results = positive_df["text"].apply(lambda x: get_top_keyword_and_score(x, positive_keyword_mapping))
    positive_results_df = positive_results.apply(pd.Series)
    positive_results_df.columns = ["keyword", "similar_sentence", "score"]
    positive_df = pd.concat([positive_df, positive_results_df], axis=1)

    # ë¶€ì • ë¦¬ë·° í‚¤ì›Œë“œ ì¶”ì¶œ
    negative_results = negative_df["text"].apply(lambda x: get_top_keyword_and_score(x, negative_keyword_mapping))
    negative_results_df = negative_results.apply(pd.Series)
    negative_results_df.columns = ["keyword", "similar_sentence", "score"]
    negative_df = pd.concat([negative_df, negative_results_df], axis=1)

    # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
    top_pos = positive_df["keyword"].value_counts().head(5)
    top_neg = negative_df["keyword"].value_counts().head(5)

    pos_list = top_pos.index.tolist()
    neg_list = [k for k in top_neg.index if k not in pos_list]
    # í‚¤ì›Œë“œ ì œì™¸(ë‚ ì”¨, í”¼ë¡œ)
    if "ë‚ ì”¨" in pos_list:
        pos_list.remove("ë‚ ì”¨")
    if "ë‚ ì”¨" in neg_list:
        neg_list.remove("ë‚ ì”¨")
    if "í”¼ë¡œ" in neg_list:
        neg_list.remove("í”¼ë¡œ")

    # ì¤‘ë³µëœ í‚¤ì›Œë“œ ì²˜ë¦¬: ê¸ì •ê³¼ ë¶€ì •ì— ëª¨ë‘ ìˆëŠ” í‚¤ì›Œë“œì—ì„œ ê°œìˆ˜ê°€ ì ì€ ìª½ì˜ í‚¤ì›Œë“œë¥¼ ì œì™¸
    for keyword in pos_list[:]:
        if keyword in neg_list:
            # ê¸ì •ê³¼ ë¶€ì •ì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œì˜ ê°œìˆ˜ ë¹„êµ
            positive_count = top_pos.get(keyword, 0)
            negative_count = top_neg.get(keyword, 0)

            if positive_count < negative_count:
                # ê¸ì •ì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œ ì œê±°
                pos_list.remove(keyword)
            elif positive_count > negative_count:
                # ë¶€ì •ì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œ ì œê±°
                neg_list.remove(keyword)
            else:
                # ê°œìˆ˜ê°€ ê°™ìœ¼ë©´ ê¸ë¶€ì • ëª¨ë‘ ì œê±°
                pos_list.remove(keyword)
                neg_list.remove(keyword)

    # ì¹´ìš´íŠ¸ê°€ 3ê°œ ì´í•˜ì¸ í‚¤ì›Œë“œ ì œê±°
    pos_list = [keyword for keyword in pos_list if top_pos[keyword] > 2]
    neg_list = [keyword for keyword in neg_list if top_neg[keyword] > 2]
            

    if len(neg_list) < 5:
        remaining = [k for k in top_neg.index if k not in neg_list and k not in pos_list]
        for k in remaining:
            if len(neg_list) < 5:
                neg_list.append(k)

    # if save:
    #     positive_df.to_excel(f"{prefix}_positive.xlsx", index=False)
    #     negative_df.to_excel(f"{prefix}_negative.xlsx", index=False)

    print("ğŸ“ˆ ê¸ì • í‚¤ì›Œë“œ:", pos_list)
    print("ğŸ“‰ ë¶€ì • í‚¤ì›Œë“œ:", neg_list)

    return pos_list, neg_list
