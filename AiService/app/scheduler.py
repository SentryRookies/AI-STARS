from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import atexit
import os
import pandas as pd
import json
from app.database import SessionLocal
from app.model import Review_summarize
from batch.emotion_model import analyze_reviews
from batch.keyword_model import extract_top_keywords

# ë§ˆì§€ë§‰ ì‘ì—… Data í™•ì¸
def load_last_processed(path="last_processed.json"):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f).get("last_processed")
    return None

# ë§ˆì§€ë§‰ ì‘ì—… Data ì €ì¥
def save_last_processed(filename, path="last_processed.json"):
    with open(path, "w", encoding="utf-8") as f:
        json.dump({"last_processed": filename}, f)

# í‚¤ì›Œë“œ ì¶”ì¶œ í”„ë¡œì„¸ì‹±
def crawl_and_analyze():
    print("ğŸ“¦ [ìŠ¤ì¼€ì¤„ëŸ¬] CSV ì½ê¸° + ë¶„ì„ ì‹œì‘")
    db = SessionLocal()
    data_dir = "./data"

    last_processed = load_last_processed()
    files = sorted(f for f in os.listdir(data_dir) if f.endswith(".csv"))

    try:
        skip = True if last_processed else False

        for file_name in files:
            if skip:
                if file_name == last_processed:
                    skip = False
                continue

            file_path = os.path.join(data_dir, file_name)
            print(f"ğŸ“‚ íŒŒì¼ ë¶„ì„ ì‹œì‘: {file_path}")

            # âœ… target_type, target_id ì¶”ì¶œ
            name_parts = file_name.replace(".csv", "").split("_")
            if len(name_parts) < 3:
                print(f"âš ï¸ íŒŒì¼ ì´ë¦„ í˜•ì‹ ì˜¤ë¥˜: {file_name}")
                continue

            target_type = name_parts[0]
            target_id = name_parts[1]

            df = pd.read_csv(file_path, encoding="utf-8-sig")
            df = df.dropna(subset=["content"])
            reviews = [{"content": text} for text in df["content"]]

            validated_data = analyze_reviews(reviews)
            validated_data = [r for r in validated_data if r and all(k in r for k in ("text", "label", "score"))]

            print(f"ê²€ì¦ëœ ë°ì´í„° ìˆ˜: {len(validated_data)}")
            analyzed_df = pd.DataFrame(validated_data)

            pos_keywords, neg_keywords = extract_top_keywords(validated_data)

            pos_count = analyzed_df[analyzed_df["label"] == "positive"].shape[0]
            neg_count = analyzed_df[analyzed_df["label"] == "negative"].shape[0]

            content_summary = (
                f"[ê¸ì • í‚¤ì›Œë“œ] {', '.join(pos_keywords)}\n"
                f"[ë¶€ì • í‚¤ì›Œë“œ] {', '.join(neg_keywords)}\n"
                f"[ê¸ì • ë¼ë²¨ ìˆ˜] {pos_count}\n"
                f"[ë¶€ì • ë¼ë²¨ ìˆ˜] {neg_count}"
            )

            # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
            existing = db.query(Review_summarize).filter_by(
                target_id=target_id,
                target_type=target_type
            ).first()

            # ê¸°ì¡´ ë°ì´í„° ì¡´ì¬ -> ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
            if existing:
                existing.content = content_summary
                print(f"ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸: {target_type}, {target_id}")
            # ê¸°ì¡´ ë°ì´í„° ì¡´ì¬ X -> ìƒˆë¡œ ìƒì„±
            else:
                summary = Review_summarize(
                    target_id=target_id,
                    target_type=target_type,
                    content=content_summary
                )
                db.add(summary)
                print(f"ìƒˆ í•­ëª© ì¶”ê°€: {target_type}, {target_id}")
            db.commit()
            print(f"{file_name} ë¶„ì„ ë° ì €ì¥ ì™„ë£Œ")

            # íŒŒì¼ ì²˜ë¦¬ í›„ ê¸°ë¡
            save_last_processed(file_name)

    except Exception as e:
        db.rollback()
        import traceback
        print("ì˜¤ë¥˜ ë°œìƒ:", repr(e))
        traceback.print_exc()
    finally:
        db.close()

# ë©”ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ í•¨ìˆ˜
def start_scheduler():
    scheduler = BackgroundScheduler()
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì¼ì • ì¡°ì ˆ
    scheduler.add_job(crawl_and_analyze, CronTrigger(hour=10, minute=0))
    scheduler.start()
    print("APScheduler ì‹œì‘ë¨")
    atexit.register(lambda: scheduler.shutdown())


if __name__ == "__main__":
    start_scheduler()
